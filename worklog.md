# WorkLog

## Table of content


## General setup.
1 - sampler parameter -> eta noise seed == 0

2 - stable diffusion -> clip skip = 0; SD VAE = {select one}


## Logs (DESC)

02-18-2023: 

- This is more proof of concept. By now, we are able to hold the model locally, and generate different images.
- One take away is to use "Save style" more frequently. As a good image is not always promised. Very often we will see strange eyes or faces.
- There are obvious patterns about key words, it will be a good idea to maintain two unique sets about useful key words.


TODO:
- next, will need to figure out how to train locally:
  - steps 
  - required data
- look into image to image (so that we can keep the same character)


